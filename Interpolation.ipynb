{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09255fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pikan.model_utils import GeneralizedMLP, FourierKAN, PirateNet\n",
    "from pikan.model_utils import get_mse_loss, get_train_step\n",
    "from pikan.model_utils import KeyHandler, sobol_sample\n",
    "from pikan.utils import load_dict_from_file, save_dict_to_file\n",
    "\n",
    "from pikan.interpolated_funcs import circular_wave_interference\n",
    "\n",
    "import yaml\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import jax\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34169b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_error(results, true):\n",
    "    err = jnp.sum((results - true)**2) / jnp.sum(true**2)\n",
    "    err = jnp.sqrt(err)\n",
    "    return err\n",
    "\n",
    "def get_l2_error(config, variables):\n",
    "    model = get_model(config)\n",
    "    learnable_func = get_target_func(experiment)\n",
    "    \n",
    "    N = 300\n",
    "    X_1 = jnp.linspace(experiment[\"X_MIN\"], experiment[\"X_MAX\"], N)\n",
    "    X_2 = jnp.linspace(experiment[\"Y_MIN\"], experiment[\"Y_MAX\"], N)\n",
    "    X_1, X_2 = jnp.meshgrid(X_1, X_2, indexing='ij')\n",
    "    coords = jnp.stack([X_1.flatten(), X_2.flatten()], axis=1)\n",
    "\n",
    "    y = learnable_func(coords).reshape(-1,1)\n",
    "\n",
    "    if config[\"MODEL\"] == \"KAN\":\n",
    "        y_hat = model.apply(variables, coords)\n",
    "    else:\n",
    "        y_hat = model.apply({\"params\": variables[\"params\"]}, coords)\n",
    "        \n",
    "    err = l2_error(y_hat, y)\n",
    "    \n",
    "    return err\n",
    "\n",
    "def sum_params(data, verbose=False):\n",
    "    total = 0\n",
    "    if isinstance(data, type(jnp.array([]))):  # If the current node is a leaf array\n",
    "        return len(data.reshape(-1))\n",
    "    elif isinstance(data, dict):  # If the current node is a dictionary\n",
    "        for key, value in data.items():\n",
    "            if verbose:\n",
    "                print(f\"Processing key: {key}\")  # Print the current key\n",
    "            branch_total = sum_params(value)  # Compute the total for this subbranch\n",
    "            if verbose:\n",
    "                print(f\"Total parameters in subbranch '{key}': {branch_total}\")\n",
    "            total += branch_total\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c200a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config):\n",
    "    if config[\"MODEL\"] == \"MLP\":\n",
    "        return GeneralizedMLP(\n",
    "            kernel_init=nn.initializers.glorot_normal(),\n",
    "            num_input=config['N_INPUT'],\n",
    "            num_output=1,\n",
    "            use_fourier_feats=config['FourierFeatures'],\n",
    "            layer_sizes=config['layers']\n",
    "        )\n",
    "    if config[\"MODEL\"] == \"KAN\":\n",
    "        return FourierKAN(\n",
    "            kernel_init=nn.initializers.glorot_normal(),\n",
    "            num_input=config['N_INPUT'],\n",
    "            num_output=1,\n",
    "            use_fourier_feats=config['FourierFeatures'],\n",
    "            layer_sizes=config['layers']\n",
    "        )\n",
    "    if config[\"MODEL\"] == \"PIRATE\":\n",
    "        return PirateNet(\n",
    "            kernel_init=nn.initializers.glorot_normal(),\n",
    "            num_input=config['N_INPUT'],\n",
    "            num_output=1,\n",
    "            layer_sizes=config['layers'] #Â first is fourier\n",
    "        )\n",
    "    \n",
    "def get_target_func(config):\n",
    "    if experiment[\"learnable_func\"] == \"circular_wave_interference\":\n",
    "        learnable_func = circular_wave_interference\n",
    "\n",
    "    learnable_func = partial(learnable_func, FREQ=experiment[\"FREQ\"])\n",
    "    return learnable_func\n",
    "\n",
    "def sample_collocs(config):\n",
    "    collocs = jnp.array(sobol_sample(np.array([config[\"X_MIN\"],config[\"Y_MIN\"]]), \n",
    "                                     np.array([config[\"X_MAX\"],config[\"Y_MAX\"]]), config[\"BS\"]))\n",
    "    return collocs\n",
    "\n",
    "def train_model(config):    \n",
    "    collocs = sample_collocs(config)\n",
    "\n",
    "    model = get_model(config)\n",
    "    variables = model.init(keygen.key(), collocs)\n",
    "    loss_fn = get_mse_loss(model, MODEL=config[\"MODEL\"])\n",
    "    \n",
    "    # Define a cosine decay learning rate schedule\n",
    "    schedule_fn = optax.cosine_decay_schedule(\n",
    "        init_value=1e-2,       # Initial learning rate\n",
    "        decay_steps=config[\"EPOCHS\"],  # Total number of decay steps\n",
    "        alpha=1e-3             # Final learning rate multiplier\n",
    "    )\n",
    "    optimizer = optax.adamw(learning_rate=schedule_fn, weight_decay=1e-4)\n",
    "    opt_state = optimizer.init(variables['params'])\n",
    "    train_step = get_train_step(model, optimizer, loss_fn)\n",
    "\n",
    "    learnable_func = get_target_func(config)\n",
    "\n",
    "    if config[\"MODEL\"] != \"KAN\":\n",
    "        variables[\"state\"] = []\n",
    "\n",
    "    # train always on same colloc points\n",
    "    collocs = sample_collocs(experiment)\n",
    "    losses = []\n",
    "\n",
    "    loc_w = jnp.array([])\n",
    "    for i in (pbar:= tqdm(range(experiment[\"EPOCHS\"]))):\n",
    "        params, state = variables['params'], variables['state']\n",
    "        y = learnable_func(collocs).reshape(-1,1)\n",
    "        params, opt_state, loss, loc_w = train_step(params, collocs, y,\n",
    "                                                    opt_state, state, loc_w)\n",
    "        variables = {'params': params, 'state':state}\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "        if i % 50 == 0: # dont waste a lot of time printing\n",
    "            pbar.set_description(f\"Loss {loss: .8f}\")\n",
    "\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "833880cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['increase_freq_1', 'increase_freq_2', 'increase_freq_3', 'increase_freq_4', 'increase_freq_5', 'increase_freq_6', 'increase_freq_7', 'increase_freq_8', 'increase_freq_9', 'increase_freq_10'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"increase_freq_KAN\"\n",
    "\n",
    "with open(f\"yaml_configs/{filename}.yaml\", 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "keygen = KeyHandler(0)\n",
    "config[\"experiments\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3c17519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase_freq_1\n",
      "12479\n",
      "increase_freq_2\n",
      "12479\n",
      "increase_freq_3\n",
      "12479\n",
      "increase_freq_4\n",
      "12479\n",
      "increase_freq_5\n",
      "12479\n",
      "increase_freq_6\n",
      "12479\n",
      "increase_freq_7\n",
      "12479\n",
      "increase_freq_8\n",
      "12479\n",
      "increase_freq_9\n",
      "12479\n",
      "increase_freq_10\n",
      "12479\n"
     ]
    }
   ],
   "source": [
    "for exp_key in config[\"experiments\"].keys():\n",
    "    experiment = config[\"experiments\"][exp_key]\n",
    "\n",
    "    collocs = sample_collocs(experiment)\n",
    "    model = get_model(experiment)\n",
    "    variables = model.init(keygen.key(), collocs)\n",
    "\n",
    "    print(exp_key)\n",
    "    print(sum_params(variables[\"params\"], verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ccbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp_key in config[\"experiments\"].keys():\n",
    "    experiment = config[\"experiments\"][exp_key]\n",
    "    variables = train_model(experiment)\n",
    "    \n",
    "    save_dict_to_file(variables, f\"results/models/{filename}\", f\"{exp_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abdf919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(config[\"experiments\"]).T\n",
    "df[\"params\"] = -1\n",
    "df[\"L2%\"] = -1\n",
    "\n",
    "for idx, exp_key in enumerate(config[\"experiments\"].keys()):\n",
    "    experiment = config[\"experiments\"][exp_key]\n",
    "    \n",
    "    variables = load_dict_from_file(f\"results/models/{filename}/{exp_key}\")\n",
    "    l2_err = get_l2_error(experiment, variables)\n",
    "\n",
    "    df.loc[exp_key, \"params\"] = sum_params(variables[\"params\"], verbose=False)\n",
    "    df.loc[exp_key, \"L2%\"] = l2_err * 100\n",
    "\n",
    "    print(f\"Results from {exp_key}:\")\n",
    "    print(f\"L2 {l2_err*100:.4f}%\")\n",
    "    print(f\"#params {df.iloc[idx]['params']}\")\n",
    "    \n",
    "df.to_csv(f\"results/csvs/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import cm\n",
    "import os\n",
    "\n",
    "def plot_true_approx(config, variables, save_folder, exp_key):\n",
    "    model = get_model(config)\n",
    "    learnable_func = get_target_func(config)  # Fixed to use 'config' instead of 'experiment'\n",
    "    \n",
    "    N = 300\n",
    "    X_1 = jnp.linspace(config[\"X_MIN\"], config[\"X_MAX\"], N)  # Fixed to use 'config'\n",
    "    X_2 = jnp.linspace(config[\"Y_MIN\"], config[\"Y_MAX\"], N)  # Fixed to use 'config'\n",
    "    X_1, X_2 = jnp.meshgrid(X_1, X_2, indexing='ij')\n",
    "    coords = jnp.stack([X_1.flatten(), X_2.flatten()], axis=1)\n",
    "\n",
    "    y = learnable_func(coords).reshape(-1, 1)\n",
    "    if config[\"MODEL\"] == \"KAN\":\n",
    "        y_hat = model.apply(variables, coords)\n",
    "    else:\n",
    "        y_hat = model.apply({\"params\": variables[\"params\"]}, coords)\n",
    "\n",
    "    y_hat = y_hat.reshape(-1, 1)\n",
    "\n",
    "    # Compute the absolute error\n",
    "    abs_error = jnp.abs(y - y_hat).reshape(-1, 1)\n",
    "\n",
    "    # Create a figure and axis grid for the 3 subplots\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Plotting the approximated function (y_hat) on the left using the plasma colormap\n",
    "    ax1 = fig.add_subplot(1, 3, 1, projection='3d')\n",
    "    ax1.plot_trisurf(coords[:, 0], coords[:, 1], y_hat.flatten(), cmap=cm.plasma)\n",
    "    ax1.set_title('Approximated Function (y_hat)')\n",
    "    ax1.set_xlabel('X1')\n",
    "    ax1.set_ylabel('X2')\n",
    "    ax1.set_zlabel('y_hat')\n",
    "\n",
    "    # Plotting the true function (y) in the middle\n",
    "    ax2 = fig.add_subplot(1, 3, 2, projection='3d')\n",
    "    ax2.plot_trisurf(coords[:, 0], coords[:, 1], y.flatten(), cmap='viridis')\n",
    "    ax2.set_title('True Function (y)')\n",
    "    ax2.set_xlabel('X1')\n",
    "    ax2.set_ylabel('X2')\n",
    "    ax2.set_zlabel('y')\n",
    "\n",
    "    # Plotting the absolute error on the right\n",
    "    ax3 = fig.add_subplot(1, 3, 3, projection='3d')\n",
    "    ax3.plot_trisurf(coords[:, 0], coords[:, 1], abs_error.flatten(), cmap='inferno')\n",
    "    ax3.set_title('Absolute Error')\n",
    "    ax3.set_xlabel('X1')\n",
    "    ax3.set_ylabel('X2')\n",
    "    ax3.set_zlabel('Error')\n",
    "\n",
    "    # Adjust layout to ensure all plots fit well within the figure\n",
    "    plt.tight_layout(pad=3.0)\n",
    "\n",
    "    # Saving the figure\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    save_path = os.path.join(save_folder, f'{exp_key}_plot.png')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Save the plot to the specified path\n",
    "    fig.savefig(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de18110",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp_key in config[\"experiments\"].keys():\n",
    "    experiment = config[\"experiments\"][exp_key]\n",
    "\n",
    "    print(f\"Results from {exp_key}:\")\n",
    "    variables = load_dict_from_file(f'results/models/{filename}/{exp_key}')\n",
    "    plot_true_approx(experiment, variables, f\"results/visuals/{filename}\", f'{exp_key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58de681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
