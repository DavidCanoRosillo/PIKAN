{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09255fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from model_utils import GeneralizedMLP, FourierKAN\n",
    "from model_utils import get_mse_loss, get_train_step\n",
    "from model_utils import KeyHandler, sobol_sample\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c200a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpolated_funcs import circular_wave_interference\n",
    "\n",
    "def get_model(config):\n",
    "    if config[\"MODEL\"] == \"MLP\":\n",
    "        return GeneralizedMLP(\n",
    "            kernel_init=nn.initializers.glorot_normal(),\n",
    "            num_input=config['N_INPUT'],\n",
    "            num_output=1,\n",
    "            use_fourier_feats=config['FourierFeatures'],\n",
    "            layer_sizes=config['layers']\n",
    "        )\n",
    "    if config[\"MODEL\"] == \"KAN\":\n",
    "        return FourierKAN(\n",
    "            kernel_init=nn.initializers.glorot_normal(),\n",
    "            num_input=config['N_INPUT'],\n",
    "            num_output=1,\n",
    "            use_fourier_feats=config['FourierFeatures'],\n",
    "            layer_sizes=config['layers']\n",
    "        )\n",
    "\n",
    "def get_target_func(config):\n",
    "    if experiment[\"learnable_func\"] == \"circular_wave_interference\":\n",
    "        learnable_func = circular_wave_interference\n",
    "\n",
    "    learnable_func = partial(learnable_func, FREQ=experiment[\"FREQ\"])\n",
    "    return learnable_func\n",
    "\n",
    "def sample_collocs(config):\n",
    "    collocs = jnp.array(sobol_sample(np.array([config[\"X_MIN\"],config[\"Y_MIN\"]]), \n",
    "                                     np.array([config[\"X_MAX\"],config[\"Y_MAX\"]]), config[\"BS\"]))\n",
    "    return collocs\n",
    "\n",
    "def train_model(config):    \n",
    "    collocs = sample_collocs(config)\n",
    "\n",
    "    model = get_model(config)\n",
    "    variables = model.init(keygen.key(), collocs)\n",
    "    loss_fn = get_mse_loss(model, MODEL=config[\"MODEL\"])\n",
    "    \n",
    "    # Define a cosine decay learning rate schedule\n",
    "    schedule_fn = optax.cosine_decay_schedule(\n",
    "        init_value=1e-2,       # Initial learning rate\n",
    "        decay_steps=config[\"EPOCHS\"],  # Total number of decay steps\n",
    "        alpha=1e-3             # Final learning rate multiplier\n",
    "    )\n",
    "    optimizer = optax.adamw(learning_rate=schedule_fn, weight_decay=1e-4)\n",
    "    opt_state = optimizer.init(variables['params'])\n",
    "    train_step = get_train_step(model, optimizer, loss_fn)\n",
    "\n",
    "    learnable_func = get_target_func(config)\n",
    "\n",
    "    if config[\"MODEL\"] == \"MLP\":\n",
    "        variables[\"state\"] = []\n",
    "\n",
    "    # train always on same colloc points\n",
    "    collocs = sample_collocs(experiment)\n",
    "    losses = []\n",
    "    \n",
    "    loc_w = jnp.array([])\n",
    "    for i in (pbar:= tqdm(range(experiment[\"EPOCHS\"]))):\n",
    "        params, state = variables['params'], variables['state']\n",
    "        y = learnable_func(collocs).reshape(-1,1)\n",
    "        params, opt_state, loss, loc_w = train_step(params, collocs, y,\n",
    "                                                    opt_state, state, loc_w)\n",
    "        variables = {'params': params, 'state':state}\n",
    "\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if i % 50 == 0: # dont waste a lot of time printing\n",
    "            pbar.set_description(f\"Loss {loss: .8f}\")\n",
    "\n",
    "    return variables, losses\n",
    "\n",
    "import pickle\n",
    "def save_dict_to_file(dictionary, filename):\n",
    "    \"\"\"Saves a dictionary to a file using pickle.\"\"\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(dictionary, file)\n",
    "\n",
    "def load_dict_from_file(filename):\n",
    "    \"\"\"Loads a dictionary from a file using pickle.\"\"\"\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833880cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['increase_params_1', 'increase_params_2', 'increase_params_3', 'increase_params_4', 'increase_params_5'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"increase_params_fourier\"\n",
    "with open(f\"{filename}.yaml\", 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "keygen = KeyHandler(0)\n",
    "config[\"experiments\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b680659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport jax \\n\\ndef get_mse_loss(model, MODEL=\\'MLP\\'):\\n    @jax.jit\\n    def mse_loss_mlp(params, x, y, state, loc_w):\\n        def u(vec_x, variables):\\n            y = model.apply(variables, vec_x)\\n            return y\\n        variables = {\\'params\\' : params}\\n        \\n        y_hat = u(x, variables)\\n        loss = (y_hat - y)**2\\n\\n        new_loc_w = loc_w\\n        return loss, new_loc_w\\n\\n    if MODEL == \\'MLP\\':\\n        return mse_loss_mlp\\n    \\n    @jax.jit\\n    def mse_loss_kan(params, x, y, state, loc_w):\\n        def u(vec_x, variables):\\n            y = model.apply(variables, vec_x)\\n            return y\\n        variables = {\\'params\\' : params, \\'state\\': state}\\n        \\n        y_hat = u(x, variables)\\n        loss = jnp.mean((y_hat - y)**2)\\n\\n        new_loc_w = loc_w\\n        return loss, new_loc_w\\n    \\n    if MODEL == \\'KAN\\':\\n        return mse_loss_kan\\n        \\nexperiment = config[\"experiments\"][\\'increase_params_1\\']\\n\\ncollocs = sample_collocs(experiment)\\ncollocs = collocs[:100]\\n\\nmodel = get_model(experiment)\\nvariables = model.init(keygen.key(), collocs)\\nloss_fn = get_mse_loss(model, MODEL=experiment[\"MODEL\"])\\n\\npreds = model.apply(variables, collocs)\\ntrue = jnp.ones_like(preds)\\nloc_w = jnp.array([])\\n\\nparams = variables[\"params\"]\\nstate = []\\n\\n\\nbatchgrad, _ = jax.jacfwd(loss_fn)(params, collocs, true, state, loc_w)\\n\\ndef compute_mean_and_std_nested(batchgrad):\\n    mean_gradients = {}\\n    std_gradients = {}\\n\\n    def traverse_and_compute(d, parent_key=\\'\\'):\\n        for key, value in d.items():\\n            full_key = f\"{parent_key}.{key}\" if parent_key else key\\n            if isinstance(value, dict):\\n                # Recurse into the nested dictionary\\n                traverse_and_compute(value, full_key)\\n            else:\\n                # Compute mean and std for the leaf-level array\\n                mean_gradients[full_key] = jnp.mean(value, axis=0)\\n                std_gradients[full_key] = jnp.std(value, axis=0)\\n\\n    traverse_and_compute(batchgrad)\\n    return mean_gradients, std_gradients\\n\\n# Compute mean and std gradients\\nmean_gradients, std_gradients = compute_mean_and_std_nested(batchgrad)\\n\\n# Compute the L2 norms of the mean and std gradients\\nmean_l2 = jnp.sqrt(sum(jnp.sum(jnp.square(mu)) for mu in mean_gradients.values()))\\nstd_l2 = jnp.sqrt(sum(jnp.sum(jnp.square(std)) for std in std_gradients.values()))\\n\\n# Compute the SNR\\nsnr = mean_l2 / std_l2\\n\\nprint(f\"SNR: {snr}\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import jax \n",
    "\n",
    "def get_mse_loss(model, MODEL='MLP'):\n",
    "    @jax.jit\n",
    "    def mse_loss_mlp(params, x, y, state, loc_w):\n",
    "        def u(vec_x, variables):\n",
    "            y = model.apply(variables, vec_x)\n",
    "            return y\n",
    "        variables = {'params' : params}\n",
    "        \n",
    "        y_hat = u(x, variables)\n",
    "        loss = (y_hat - y)**2\n",
    "\n",
    "        new_loc_w = loc_w\n",
    "        return loss, new_loc_w\n",
    "\n",
    "    if MODEL == 'MLP':\n",
    "        return mse_loss_mlp\n",
    "    \n",
    "    @jax.jit\n",
    "    def mse_loss_kan(params, x, y, state, loc_w):\n",
    "        def u(vec_x, variables):\n",
    "            y = model.apply(variables, vec_x)\n",
    "            return y\n",
    "        variables = {'params' : params, 'state': state}\n",
    "        \n",
    "        y_hat = u(x, variables)\n",
    "        loss = jnp.mean((y_hat - y)**2)\n",
    "\n",
    "        new_loc_w = loc_w\n",
    "        return loss, new_loc_w\n",
    "    \n",
    "    if MODEL == 'KAN':\n",
    "        return mse_loss_kan\n",
    "        \n",
    "experiment = config[\"experiments\"]['increase_params_1']\n",
    "\n",
    "collocs = sample_collocs(experiment)\n",
    "collocs = collocs[:100]\n",
    "\n",
    "model = get_model(experiment)\n",
    "variables = model.init(keygen.key(), collocs)\n",
    "loss_fn = get_mse_loss(model, MODEL=experiment[\"MODEL\"])\n",
    "\n",
    "preds = model.apply(variables, collocs)\n",
    "true = jnp.ones_like(preds)\n",
    "loc_w = jnp.array([])\n",
    "\n",
    "params = variables[\"params\"]\n",
    "state = []\n",
    "\n",
    "\n",
    "batchgrad, _ = jax.jacfwd(loss_fn)(params, collocs, true, state, loc_w)\n",
    "\n",
    "def compute_mean_and_std_nested(batchgrad):\n",
    "    mean_gradients = {}\n",
    "    std_gradients = {}\n",
    "\n",
    "    def traverse_and_compute(d, parent_key=''):\n",
    "        for key, value in d.items():\n",
    "            full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "            if isinstance(value, dict):\n",
    "                # Recurse into the nested dictionary\n",
    "                traverse_and_compute(value, full_key)\n",
    "            else:\n",
    "                # Compute mean and std for the leaf-level array\n",
    "                mean_gradients[full_key] = jnp.mean(value, axis=0)\n",
    "                std_gradients[full_key] = jnp.std(value, axis=0)\n",
    "\n",
    "    traverse_and_compute(batchgrad)\n",
    "    return mean_gradients, std_gradients\n",
    "\n",
    "# Compute mean and std gradients\n",
    "mean_gradients, std_gradients = compute_mean_and_std_nested(batchgrad)\n",
    "\n",
    "# Compute the L2 norms of the mean and std gradients\n",
    "mean_l2 = jnp.sqrt(sum(jnp.sum(jnp.square(mu)) for mu in mean_gradients.values()))\n",
    "std_l2 = jnp.sqrt(sum(jnp.sum(jnp.square(std)) for std in std_gradients.values()))\n",
    "\n",
    "# Compute the SNR\n",
    "snr = mean_l2 / std_l2\n",
    "\n",
    "print(f\"SNR: {snr}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "037ccbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open URL in browser: https://ui.perfetto.dev/#!/?url=http://127.0.0.1:9001/perfetto_trace.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Dec/2024 10:46:26] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Dec/2024 10:46:34] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Dec/2024 10:46:45] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Dec/2024 10:46:49] code 501, message Unsupported method ('OPTIONS')\n",
      "127.0.0.1 - - [12/Dec/2024 10:46:49] \"OPTIONS /status HTTP/1.1\" 501 -\n",
      "127.0.0.1 - - [12/Dec/2024 10:46:49] code 404, message File not found\n",
      "127.0.0.1 - - [12/Dec/2024 10:46:49] \"POST /status HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [12/Dec/2024 10:46:49] code 501, message Unsupported method ('OPTIONS')\n",
      "127.0.0.1 - - [12/Dec/2024 10:46:49] \"OPTIONS /perfetto_trace.json.gz HTTP/1.1\" 501 -\n",
      "127.0.0.1 - - [12/Dec/2024 10:46:49] \"GET /perfetto_trace.json.gz HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict_keys' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mtrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/jax-trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, create_perfetto_link\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):    \n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m exp_key \u001b[38;5;129;01min\u001b[39;00m \u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexperiments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m      5\u001b[0m         experiment \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiments\u001b[39m\u001b[38;5;124m\"\u001b[39m][exp_key]\n\u001b[1;32m      6\u001b[0m         variables, losses \u001b[38;5;241m=\u001b[39m train_model(experiment)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict_keys' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import jax \n",
    "\n",
    "with jax.profiler.trace(\"/tmp/jax-trace\", create_perfetto_link=True):    \n",
    "    for exp_key in config[\"experiments\"].keys():\n",
    "        experiment = config[\"experiments\"][exp_key]\n",
    "        variables, losses = train_model(experiment)\n",
    "        save_dict_to_file(variables, f\"trained_models/{exp_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee02137",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables[\"params\"][\"KAN_0\"][\"layers_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a079f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables[\"state\"][\"KAN_0\"][\"layers_0\"][\"grid\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84bc37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_error(results, true):\n",
    "    err = jnp.sum((results - true)**2) / jnp.sum(true**2)\n",
    "    err = jnp.sqrt(err)\n",
    "    return err\n",
    "\n",
    "def get_l2_error(config, variables):\n",
    "    model = get_model(config)\n",
    "    learnable_func = get_target_func(experiment)\n",
    "    \n",
    "    N = 300\n",
    "    X_1 = jnp.linspace(experiment[\"X_MIN\"], experiment[\"X_MAX\"], N)\n",
    "    X_2 = jnp.linspace(experiment[\"Y_MIN\"], experiment[\"Y_MAX\"], N)\n",
    "    X_1, X_2 = jnp.meshgrid(X_1, X_2, indexing='ij')\n",
    "    coords = jnp.stack([X_1.flatten(), X_2.flatten()], axis=1)\n",
    "\n",
    "    y = learnable_func(coords).reshape(-1,1)\n",
    "    y_hat = model.apply(variables, coords)\n",
    "    \n",
    "    err = l2_error(y_hat, y)\n",
    "    \n",
    "    return err\n",
    "\n",
    "def sum_params(data, verbose=False):\n",
    "    total = 0\n",
    "    if isinstance(data, type(jnp.array([]))):  # If the current node is a leaf array\n",
    "        return len(data.reshape(-1))\n",
    "    elif isinstance(data, dict):  # If the current node is a dictionary\n",
    "        for key, value in data.items():\n",
    "            if verbose:\n",
    "                print(f\"Processing key: {key}\")  # Print the current key\n",
    "            branch_total = sum_params(value)  # Compute the total for this subbranch\n",
    "            if verbose:\n",
    "                print(f\"Total parameters in subbranch '{key}': {branch_total}\")\n",
    "            total += branch_total\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abdf919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(config[\"experiments\"]).T\n",
    "df[\"params\"] = -1\n",
    "df[\"L2%\"] = -1\n",
    "\n",
    "for idx, exp_key in enumerate(config[\"experiments\"].keys()):\n",
    "    experiment = config[\"experiments\"][exp_key]\n",
    "    \n",
    "    variables = load_dict_from_file(f\"trained_models/{exp_key}\")\n",
    "    l2_err = get_l2_error(experiment, variables)\n",
    "\n",
    "    df.loc[exp_key, \"params\"] = sum_params(variables[\"params\"], verbose=False)\n",
    "    df.loc[exp_key, \"L2%\"] = l2_err * 100\n",
    "\n",
    "    print(f\"Results from {exp_key}:\")\n",
    "    print(f\"L2 {l2_err*100:.4f}%\")\n",
    "    print(f\"#params {df.iloc[idx]['params']}\")\n",
    "    \n",
    "df.to_csv(f'{filename}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import cm\n",
    "import os\n",
    "\n",
    "def plot_true_approx(config, variables, exp_key):\n",
    "    model = get_model(config)\n",
    "    learnable_func = get_target_func(config)  # Fixed to use 'config' instead of 'experiment'\n",
    "    \n",
    "    N = 300\n",
    "    X_1 = jnp.linspace(config[\"X_MIN\"], config[\"X_MAX\"], N)  # Fixed to use 'config'\n",
    "    X_2 = jnp.linspace(config[\"Y_MIN\"], config[\"Y_MAX\"], N)  # Fixed to use 'config'\n",
    "    X_1, X_2 = jnp.meshgrid(X_1, X_2, indexing='ij')\n",
    "    coords = jnp.stack([X_1.flatten(), X_2.flatten()], axis=1)\n",
    "\n",
    "    y = learnable_func(coords).reshape(-1, 1)\n",
    "    y_hat = model.apply(variables, coords).reshape(-1, 1)\n",
    "\n",
    "    # Compute the absolute error\n",
    "    abs_error = jnp.abs(y - y_hat).reshape(-1, 1)\n",
    "\n",
    "    # Create a figure and axis grid for the 3 subplots\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Plotting the approximated function (y_hat) on the left using the plasma colormap\n",
    "    ax1 = fig.add_subplot(1, 3, 1, projection='3d')\n",
    "    ax1.plot_trisurf(coords[:, 0], coords[:, 1], y_hat.flatten(), cmap=cm.plasma)\n",
    "    ax1.set_title('Approximated Function (y_hat)')\n",
    "    ax1.set_xlabel('X1')\n",
    "    ax1.set_ylabel('X2')\n",
    "    ax1.set_zlabel('y_hat')\n",
    "\n",
    "    # Plotting the true function (y) in the middle\n",
    "    ax2 = fig.add_subplot(1, 3, 2, projection='3d')\n",
    "    ax2.plot_trisurf(coords[:, 0], coords[:, 1], y.flatten(), cmap='viridis')\n",
    "    ax2.set_title('True Function (y)')\n",
    "    ax2.set_xlabel('X1')\n",
    "    ax2.set_ylabel('X2')\n",
    "    ax2.set_zlabel('y')\n",
    "\n",
    "    # Plotting the absolute error on the right\n",
    "    ax3 = fig.add_subplot(1, 3, 3, projection='3d')\n",
    "    ax3.plot_trisurf(coords[:, 0], coords[:, 1], abs_error.flatten(), cmap='inferno')\n",
    "    ax3.set_title('Absolute Error')\n",
    "    ax3.set_xlabel('X1')\n",
    "    ax3.set_ylabel('X2')\n",
    "    ax3.set_zlabel('Error')\n",
    "\n",
    "    # Adjust layout to ensure all plots fit well within the figure\n",
    "    plt.tight_layout(pad=3.0)\n",
    "\n",
    "    # Saving the figure\n",
    "    save_folder = f'visuals/{filename}'\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    save_path = os.path.join(save_folder, f'{exp_key}_plot.png')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Save the plot to the specified path\n",
    "    fig.savefig(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de18110",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp_key in config[\"experiments\"].keys():\n",
    "    experiment = config[\"experiments\"][exp_key]\n",
    "\n",
    "    print(f\"Results from {exp_key}:\")\n",
    "    variables = load_dict_from_file(f'trained_models/{filename}/{exp_key}')\n",
    "    plot_true_approx(experiment,variables, f'{exp_key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efebb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('increase_params_fourier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc84245",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('KAN_increase_params_fourier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb21f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(experiment)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2147909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_params(variables[\"params\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af2a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a37559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a829ecd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
