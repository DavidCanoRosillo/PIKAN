{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09255fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from model_utils import GeneralizedMLP, FourierKAN\n",
    "from model_utils import get_mse_loss, get_train_step\n",
    "from model_utils import KeyHandler, sobol_sample\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c200a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpolated_funcs import circular_wave_interference\n",
    "\n",
    "def get_model(config):\n",
    "    if config[\"MODEL\"] == \"MLP\":\n",
    "        return GeneralizedMLP(\n",
    "            kernel_init=nn.initializers.glorot_normal(),\n",
    "            num_input=config['N_INPUT'],\n",
    "            num_output=1,\n",
    "            use_fourier_feats=config['FourierFeatures'],\n",
    "            layer_sizes=config['layers']\n",
    "        )\n",
    "    if config[\"MODEL\"] == \"KAN\":\n",
    "        return FourierKAN(\n",
    "            kernel_init=nn.initializers.glorot_normal(),\n",
    "            num_input=config['N_INPUT'],\n",
    "            num_output=1,\n",
    "            use_fourier_feats=config['FourierFeatures'],\n",
    "            layer_sizes=config['layers']\n",
    "        )\n",
    "\n",
    "def get_target_func(config):\n",
    "    if experiment[\"learnable_func\"] == \"circular_wave_interference\":\n",
    "        learnable_func = circular_wave_interference\n",
    "\n",
    "    learnable_func = partial(learnable_func, FREQ=experiment[\"FREQ\"])\n",
    "    return learnable_func\n",
    "\n",
    "def sample_collocs(config):\n",
    "    collocs = jnp.array(sobol_sample(np.array([config[\"X_MIN\"],config[\"Y_MIN\"]]), \n",
    "                                     np.array([config[\"X_MAX\"],config[\"Y_MAX\"]]), config[\"BS\"]))\n",
    "    return collocs\n",
    "\n",
    "def train_model(config):    \n",
    "    collocs = sample_collocs(config)\n",
    "\n",
    "    model = get_model(config)\n",
    "    variables = model.init(keygen.key(), collocs)\n",
    "    loss_fn = get_mse_loss(model, MODEL=config[\"MODEL\"])\n",
    "    \n",
    "    # Define a cosine decay learning rate schedule\n",
    "    schedule_fn = optax.cosine_decay_schedule(\n",
    "        init_value=1e-2,       # Initial learning rate\n",
    "        decay_steps=config[\"EPOCHS\"],  # Total number of decay steps\n",
    "        alpha=1e-3             # Final learning rate multiplier\n",
    "    )\n",
    "    optimizer = optax.adamw(learning_rate=schedule_fn, weight_decay=1e-4)\n",
    "    opt_state = optimizer.init(variables['params'])\n",
    "    train_step = get_train_step(model, optimizer, loss_fn)\n",
    "\n",
    "    learnable_func = get_target_func(config)\n",
    "\n",
    "    if config[\"MODEL\"] == \"MLP\":\n",
    "        variables[\"state\"] = []\n",
    "\n",
    "    # train always on same colloc points\n",
    "    collocs = sample_collocs(experiment)\n",
    "    losses = []\n",
    "    \n",
    "    loc_w = jnp.array([])\n",
    "    for i in (pbar:= tqdm(range(experiment[\"EPOCHS\"]))):\n",
    "        params, state = variables['params'], variables['state']\n",
    "        y = learnable_func(collocs).reshape(-1,1)\n",
    "        params, opt_state, loss, loc_w = train_step(params, collocs, y,\n",
    "                                                    opt_state, state, loc_w)\n",
    "        variables = {'params': params, 'state':state}\n",
    "\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if i % 50 == 0: # dont waste a lot of time printing\n",
    "            pbar.set_description(f\"Loss {loss: .8f}\")\n",
    "\n",
    "    return variables, losses\n",
    "\n",
    "import pickle\n",
    "def save_dict_to_file(dictionary, filename):\n",
    "    \"\"\"Saves a dictionary to a file using pickle.\"\"\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(dictionary, file)\n",
    "\n",
    "def load_dict_from_file(filename):\n",
    "    \"\"\"Loads a dictionary from a file using pickle.\"\"\"\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833880cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['increase_params_1', 'increase_params_2', 'increase_params_3', 'increase_params_4', 'increase_params_5'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"increase_params_fourier\"\n",
    "with open(f\"{filename}.yaml\", 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "keygen = KeyHandler(0)\n",
    "config[\"experiments\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b680659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dense_0': {'bias': Array([[-1.0785582]], dtype=float32),\n",
       "  'kernel': Array([[[ 1.0503103 ],\n",
       "          [-0.9971523 ],\n",
       "          [-0.9746476 ],\n",
       "          [-0.2376494 ],\n",
       "          [-1.076255  ],\n",
       "          [-0.93965465],\n",
       "          [ 0.5540534 ],\n",
       "          [ 0.5681294 ],\n",
       "          [ 1.0190935 ],\n",
       "          [ 0.5734641 ],\n",
       "          [-1.0649058 ],\n",
       "          [-1.0368441 ],\n",
       "          [ 1.0537382 ],\n",
       "          [ 1.0652359 ],\n",
       "          [-0.79729855],\n",
       "          [ 0.50856835],\n",
       "          [ 0.24522667],\n",
       "          [ 0.4110658 ],\n",
       "          [ 0.46189806],\n",
       "          [ 1.0520507 ],\n",
       "          [ 0.07044991],\n",
       "          [-0.5294685 ],\n",
       "          [-0.9253716 ],\n",
       "          [-0.916797  ],\n",
       "          [-0.35318023],\n",
       "          [-0.9134696 ],\n",
       "          [-0.17106532],\n",
       "          [-0.29705578],\n",
       "          [-0.23005116],\n",
       "          [-0.16899806],\n",
       "          [ 0.7263627 ],\n",
       "          [ 0.9511288 ]]], dtype=float32)},\n",
       " 'FourierFeats_0': {'B': Array([[[ 0.04291802, -0.09637446, -0.15213463,  0.01053628,\n",
       "            0.09130981, -0.11698367,  0.00503994,  0.05127643,\n",
       "           -0.00182579, -0.04520562, -0.00368114, -0.04470647,\n",
       "           -0.08412447, -0.01093813,  0.03810528, -0.03843166],\n",
       "          [ 0.06331226, -0.14217068, -0.22442757,  0.01554302,\n",
       "            0.13469936, -0.1725732 ,  0.00743488,  0.0756425 ,\n",
       "           -0.00269339, -0.06668691, -0.00543038, -0.06595057,\n",
       "           -0.12409962, -0.01613582,  0.05621255, -0.05669401]]],      dtype=float32),\n",
       "  'bias': Array([[-0.12461197,  0.27982208,  0.44172108, -0.03059195, -0.26511693,\n",
       "           0.33966067, -0.01463342, -0.1488805 ,  0.00530117,  0.13125399,\n",
       "           0.01068814,  0.1298047 ,  0.24425438,  0.03175872, -0.11063822,\n",
       "           0.11158585]], dtype=float32)}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax \n",
    "\n",
    "def get_mse_loss(model, MODEL='MLP'):\n",
    "#    @jax.jit\n",
    "    def mse_loss_mlp(params, x, y, state):\n",
    "        def u(vec_x, variables):\n",
    "            y = model.apply(variables, vec_x)\n",
    "            return y\n",
    "        variables = {'params' : params}\n",
    "        \n",
    "        y_hat = u(x, variables)\n",
    "        loss = (y_hat - y)**2\n",
    "#        print(jnp.squeeze(loss))\n",
    "        \n",
    "        return jnp.squeeze(loss)\n",
    "\n",
    "    if MODEL == 'MLP':\n",
    "        return mse_loss_mlp\n",
    "    \n",
    "    @jax.jit\n",
    "    def mse_loss_kan(params, x, y, state, loc_w):\n",
    "        def u(vec_x, variables):\n",
    "            y = model.apply(variables, vec_x)\n",
    "            return y\n",
    "        variables = {'params' : params, 'state': state}\n",
    "        \n",
    "        y_hat = u(x, variables)\n",
    "        loss = jnp.mean((y_hat - y)**2)\n",
    "\n",
    "        new_loc_w = loc_w\n",
    "        return loss, new_loc_w\n",
    "    \n",
    "    if MODEL == 'KAN':\n",
    "        return mse_loss_kan\n",
    "        \n",
    "experiment = config[\"experiments\"]['increase_params_1']\n",
    "\n",
    "collocs = sample_collocs(experiment)\n",
    "collocs = collocs[:1]\n",
    "\n",
    "model = get_model(experiment)\n",
    "variables = model.init(keygen.key(), collocs)\n",
    "loss_fn = get_mse_loss(model, MODEL=experiment[\"MODEL\"])\n",
    "\n",
    "preds = model.apply(variables, collocs)\n",
    "true = jnp.ones_like(preds)\n",
    "\n",
    "loc_w = jnp.array([])\n",
    "\n",
    "params = variables[\"params\"]\n",
    "state = []\n",
    "\n",
    "\n",
    "res = jax.vmap(loss_fn, (None, 0, 0, None))(params, collocs, true, state)\n",
    "loss_grad = jax.value_and_grad(loss_fn)\n",
    "\n",
    "res, grads = jax.vmap(loss_grad, (None, 0, 0, None))(params, collocs, true, state)\n",
    "#Â grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_and_std_nested(batchgrad):\n",
    "    mean_gradients = {}\n",
    "    std_gradients = {}\n",
    "\n",
    "    def traverse_and_compute(d, parent_key=''):\n",
    "        for key, value in d.items():\n",
    "            full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "            if isinstance(value, dict):\n",
    "                # Recurse into the nested dictionary\n",
    "                traverse_and_compute(value, full_key)\n",
    "            else:\n",
    "                # Compute mean and std for the leaf-level array\n",
    "                mean_gradients[full_key] = jnp.mean(value, axis=0)\n",
    "                std_gradients[full_key] = jnp.std(value, axis=0)\n",
    "\n",
    "    traverse_and_compute(batchgrad)\n",
    "    return mean_gradients, std_gradients\n",
    "\n",
    "# Compute mean and std gradients\n",
    "mean_gradients, std_gradients = compute_mean_and_std_nested(batchgrad)\n",
    "\n",
    "# Compute the L2 norms of the mean and std gradients\n",
    "mean_l2 = jnp.sqrt(sum(jnp.sum(jnp.square(mu)) for mu in mean_gradients.values()))\n",
    "std_l2 = jnp.sqrt(sum(jnp.sum(jnp.square(std)) for std in std_gradients.values()))\n",
    "\n",
    "# Compute the SNR\n",
    "snr = mean_l2 / std_l2\n",
    "\n",
    "print(f\"SNR: {snr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ccbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp_key in config[\"experiments\"].keys():\n",
    "    experiment = config[\"experiments\"][exp_key]\n",
    "    variables, losses = train_model(experiment)\n",
    "    save_dict_to_file(variables, f\"trained_models/{exp_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84bc37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_error(results, true):\n",
    "    err = jnp.sum((results - true)**2) / jnp.sum(true**2)\n",
    "    err = jnp.sqrt(err)\n",
    "    return err\n",
    "\n",
    "def get_l2_error(config, variables):\n",
    "    model = get_model(config)\n",
    "    learnable_func = get_target_func(experiment)\n",
    "    \n",
    "    N = 300\n",
    "    X_1 = jnp.linspace(experiment[\"X_MIN\"], experiment[\"X_MAX\"], N)\n",
    "    X_2 = jnp.linspace(experiment[\"Y_MIN\"], experiment[\"Y_MAX\"], N)\n",
    "    X_1, X_2 = jnp.meshgrid(X_1, X_2, indexing='ij')\n",
    "    coords = jnp.stack([X_1.flatten(), X_2.flatten()], axis=1)\n",
    "\n",
    "    y = learnable_func(coords).reshape(-1,1)\n",
    "    y_hat = model.apply(variables, coords)\n",
    "    \n",
    "    err = l2_error(y_hat, y)\n",
    "    \n",
    "    return err\n",
    "\n",
    "def sum_params(data, verbose=False):\n",
    "    total = 0\n",
    "    if isinstance(data, type(jnp.array([]))):  # If the current node is a leaf array\n",
    "        return len(data.reshape(-1))\n",
    "    elif isinstance(data, dict):  # If the current node is a dictionary\n",
    "        for key, value in data.items():\n",
    "            if verbose:\n",
    "                print(f\"Processing key: {key}\")  # Print the current key\n",
    "            branch_total = sum_params(value)  # Compute the total for this subbranch\n",
    "            if verbose:\n",
    "                print(f\"Total parameters in subbranch '{key}': {branch_total}\")\n",
    "            total += branch_total\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abdf919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(config[\"experiments\"]).T\n",
    "df[\"params\"] = -1\n",
    "df[\"L2%\"] = -1\n",
    "\n",
    "for idx, exp_key in enumerate(config[\"experiments\"].keys()):\n",
    "    experiment = config[\"experiments\"][exp_key]\n",
    "    \n",
    "    variables = load_dict_from_file(f\"trained_models/{exp_key}\")\n",
    "    l2_err = get_l2_error(experiment, variables)\n",
    "\n",
    "    df.loc[exp_key, \"params\"] = sum_params(variables[\"params\"], verbose=False)\n",
    "    df.loc[exp_key, \"L2%\"] = l2_err * 100\n",
    "\n",
    "    print(f\"Results from {exp_key}:\")\n",
    "    print(f\"L2 {l2_err*100:.4f}%\")\n",
    "    print(f\"#params {df.iloc[idx]['params']}\")\n",
    "    \n",
    "df.to_csv(f'{filename}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import cm\n",
    "import os\n",
    "\n",
    "def plot_true_approx(config, variables, exp_key):\n",
    "    model = get_model(config)\n",
    "    learnable_func = get_target_func(config)  # Fixed to use 'config' instead of 'experiment'\n",
    "    \n",
    "    N = 300\n",
    "    X_1 = jnp.linspace(config[\"X_MIN\"], config[\"X_MAX\"], N)  # Fixed to use 'config'\n",
    "    X_2 = jnp.linspace(config[\"Y_MIN\"], config[\"Y_MAX\"], N)  # Fixed to use 'config'\n",
    "    X_1, X_2 = jnp.meshgrid(X_1, X_2, indexing='ij')\n",
    "    coords = jnp.stack([X_1.flatten(), X_2.flatten()], axis=1)\n",
    "\n",
    "    y = learnable_func(coords).reshape(-1, 1)\n",
    "    y_hat = model.apply(variables, coords).reshape(-1, 1)\n",
    "\n",
    "    # Compute the absolute error\n",
    "    abs_error = jnp.abs(y - y_hat).reshape(-1, 1)\n",
    "\n",
    "    # Create a figure and axis grid for the 3 subplots\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Plotting the approximated function (y_hat) on the left using the plasma colormap\n",
    "    ax1 = fig.add_subplot(1, 3, 1, projection='3d')\n",
    "    ax1.plot_trisurf(coords[:, 0], coords[:, 1], y_hat.flatten(), cmap=cm.plasma)\n",
    "    ax1.set_title('Approximated Function (y_hat)')\n",
    "    ax1.set_xlabel('X1')\n",
    "    ax1.set_ylabel('X2')\n",
    "    ax1.set_zlabel('y_hat')\n",
    "\n",
    "    # Plotting the true function (y) in the middle\n",
    "    ax2 = fig.add_subplot(1, 3, 2, projection='3d')\n",
    "    ax2.plot_trisurf(coords[:, 0], coords[:, 1], y.flatten(), cmap='viridis')\n",
    "    ax2.set_title('True Function (y)')\n",
    "    ax2.set_xlabel('X1')\n",
    "    ax2.set_ylabel('X2')\n",
    "    ax2.set_zlabel('y')\n",
    "\n",
    "    # Plotting the absolute error on the right\n",
    "    ax3 = fig.add_subplot(1, 3, 3, projection='3d')\n",
    "    ax3.plot_trisurf(coords[:, 0], coords[:, 1], abs_error.flatten(), cmap='inferno')\n",
    "    ax3.set_title('Absolute Error')\n",
    "    ax3.set_xlabel('X1')\n",
    "    ax3.set_ylabel('X2')\n",
    "    ax3.set_zlabel('Error')\n",
    "\n",
    "    # Adjust layout to ensure all plots fit well within the figure\n",
    "    plt.tight_layout(pad=3.0)\n",
    "\n",
    "    # Saving the figure\n",
    "    save_folder = f'visuals/{filename}'\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    save_path = os.path.join(save_folder, f'{exp_key}_plot.png')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Save the plot to the specified path\n",
    "    fig.savefig(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de18110",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp_key in config[\"experiments\"].keys():\n",
    "    experiment = config[\"experiments\"][exp_key]\n",
    "\n",
    "    print(f\"Results from {exp_key}:\")\n",
    "    variables = load_dict_from_file(f'trained_models/{filename}/{exp_key}')\n",
    "    plot_true_approx(experiment,variables, f'{exp_key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efebb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('increase_params_fourier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc84245",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('KAN_increase_params_fourier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb21f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(experiment)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2147909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_params(variables[\"params\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af2a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a37559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a829ecd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
